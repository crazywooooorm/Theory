## Nonparametric Statistics

### Difference of parametric and nonparametric statistics

##### Pros
* Doesn't depend on shape of distributions or other assumptions (assumptions
of distribution are actually pretty difficult to meet in many cases).
* Easy to apply.
* Deals with data with different [measurements](https://github.com/crazywooooorm/Theory/blob/master/Statistics/Nonparametric/book_review.md).

##### Cons
* Might lose power and information when the assumptions on distributions are
actually met.
* Needs some [approximation](https://en.wikipedia.org/wiki/Central_limit_theorem) in big sample cases.

### Why do we learn Nonparametric methods
We don't need to remember the formulas of those nonparametric statistical
tests because most of them just work for a specific measurement and design.
What really matters are those ideas behind different nonparametric methods, they
help us jump out of the restrictions of classical distributions and think about
the data in different ways.

### Some examples

##### Goodness of fit: Kolmogorovâ€“Smirnov test
[Two Sample Case](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test)

##### Rank statistic: Wilcoxon Signed-Rank Test
[Fish Length Case](https://onlinecourses.science.psu.edu/stat414/node/319/)

##### Resampling: Permutation test & Boostrap
[Fisher's Exact Test](https://en.wikipedia.org/wiki/Fisher%27s_exact_test#Example)
